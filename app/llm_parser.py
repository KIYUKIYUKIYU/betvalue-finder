# -*- coding: utf-8 -*-
"""
LLMãƒ™ãƒ¼ã‚¹è‡ªå‹•ãƒ‘ãƒ¼ã‚µãƒ¼
å®Œå…¨è‡ªå‹•ã§NPB/MLB/ã‚µãƒƒã‚«ãƒ¼ã®ãƒ™ãƒƒãƒ†ã‚£ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’è§£æ
"""

import json
import re
from typing import List, Dict, Optional, Any
from dataclasses import dataclass
import logging

@dataclass
class LLMParseResult:
    """LLMãƒ‘ãƒ¼ã‚¹çµæœ"""
    games: List[Dict]
    confidence: float
    method_used: str
    processing_time: float
    raw_response: str


class LLMBettingParser:
    """LLMé§†å‹•ã®å®Œå…¨è‡ªå‹•ãƒ™ãƒƒãƒ†ã‚£ãƒ³ã‚°ãƒ‘ãƒ¼ã‚µãƒ¼"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)

        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        self.system_prompt = """
ã‚ãªãŸã¯ä¸–ç•Œæœ€é«˜ã®ã‚¹ãƒãƒ¼ãƒ„ãƒ™ãƒƒãƒ†ã‚£ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿è§£æå°‚é–€å®¶ã§ã™ã€‚

ä»»å‹™ï¼š
å…¥åŠ›ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ™ãƒƒãƒ†ã‚£ãƒ³ã‚°æƒ…å ±ï¼ˆè©¦åˆã¨ãƒãƒ³ãƒ‡ã‚£ã‚­ãƒ£ãƒƒãƒ—ï¼‰ã‚’å®Œå…¨è‡ªå‹•ã§æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

å‡ºåŠ›å½¢å¼ï¼š
å¿…ãšJSONå½¢å¼ã§ä»¥ä¸‹ã®æ§‹é€ ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

{
  "games": [
    {
      "team_a": "ãƒãƒ¼ãƒ 1å",
      "team_b": "ãƒãƒ¼ãƒ 2å",
      "handicap": "ãƒãƒ³ãƒ‡ã‚£ã‚­ãƒ£ãƒƒãƒ—å€¤",
      "fav_team": "ãƒ•ã‚§ã‚¤ãƒãƒªãƒƒãƒˆãƒãƒ¼ãƒ å",
      "sport": "npb|mlb|soccer|champions_league",
      "game_time": "è©¦åˆæ™‚åˆ»",
      "confidence": 0.0-1.0ã®ä¿¡é ¼åº¦
    }
  ],
  "analysis": "è§£æéç¨‹ã®èª¬æ˜",
  "deadline": "ç· åˆ‡æ™‚åˆ»ï¼ˆã‚ã‚Œã°ï¼‰"
}

é‡è¦ãªãƒ«ãƒ¼ãƒ«ï¼š
1. ãƒãƒ¼ãƒ åã¯æ­£å¼åç§°ã«çµ±ä¸€
2. ãƒãƒ³ãƒ‡ã‚£ã‚­ãƒ£ãƒƒãƒ—å¤‰æ›ãƒ«ãƒ¼ãƒ«ï¼š
   - NPB: <07>â†’0.7ã€<02>â†’0.2ã€<0>â†’0
   - Soccer: <0>â†’0ã€<0/5>â†’0.5ã€<0åŠ7>â†’0.5ã€<2åŠ5>â†’2.5
3. ãƒ•ã‚§ã‚¤ãƒãƒªãƒƒãƒˆã¯ãƒãƒ³ãƒ‡ã‚£ã‚­ãƒ£ãƒƒãƒ—ãŒä»˜ã„ã¦ã„ã‚‹ãƒãƒ¼ãƒ 
4. æ™‚åˆ»æƒ…å ±ï¼š25:45â†’ç¿Œæ—¥01:45ã€28:00â†’ç¿Œæ—¥04:00ã¨ã—ã¦è¨˜éŒ²
5. ç©ºè¡Œã¯è©¦åˆåŒºåˆ‡ã‚Šã¨ã—ã¦æ‰±ã†
6. ç· åˆ‡æƒ…å ±ï¼ˆï¼Š20:00ã€†åˆ‡ã‚Šï¼‰ã¯æŠ½å‡ºã—ã¦ deadline ã«è¨­å®š
7. ã‚¹ãƒãƒ¼ãƒ„è‡ªå‹•åˆ¤å®šï¼šCLãªã‚‰champions_leagueã€NPBãƒãƒ¼ãƒ ãªã‚‰npb

NPBãƒãƒ¼ãƒ åãƒãƒƒãƒ”ãƒ³ã‚°ï¼š
- ã‚½ãƒ•ãƒˆ/ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯ â†’ ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯
- æ¨ªæµœ â†’ DeNA
- æ—¥ãƒãƒ  â†’ æ—¥æœ¬ãƒãƒ 

ã‚µãƒƒã‚«ãƒ¼ãƒãƒ¼ãƒ åãƒãƒƒãƒ”ãƒ³ã‚°ï¼š
- ãƒãƒ³ãƒã‚§ã‚¹ã‚¿ãƒ¼C â†’ Manchester City
- ãƒãƒ«ã‚»ãƒ­ãƒŠ â†’ Barcelona
- ãƒ¬ãƒ´ã‚¡ãƒ¼ã‚¯ãƒ¼ã‚¼ãƒ³ â†’ Bayer Leverkusen
- ãã®ä»–ã¯åŸºæœ¬çš„ã«ãã®ã¾ã¾
"""

    def parse(self, text: str, sport: str = "auto") -> LLMParseResult:
        """LLMã‚’ä½¿ç”¨ã—ãŸå®Œå…¨è‡ªå‹•ãƒ‘ãƒ¼ã‚¹"""
        import time
        start_time = time.time()

        try:
            # OpenAI GPT-4ã‚’ä½¿ç”¨ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ API ã‚­ãƒ¼è¨­å®šãŒå¿…è¦ï¼‰
            response = self._call_llm(text, sport)

            # JSONãƒ‘ãƒ¼ã‚¹
            games_data = self._parse_llm_response(response)

            processing_time = time.time() - start_time

            return LLMParseResult(
                games=games_data.get("games", []),
                confidence=self._calculate_overall_confidence(games_data.get("games", [])),
                method_used="llm_gpt4",
                processing_time=processing_time,
                raw_response=response
            )

        except Exception as e:
            self.logger.error(f"LLM parsing failed: {e}")
            return self._fallback_parse(text)

    def _call_llm(self, text: str, sport: str) -> str:
        """ãƒ­ãƒ¼ã‚«ãƒ«é«˜ç²¾åº¦è§£æ (External APIä¸è¦)"""
        # å¸¸ã«ãƒ­ãƒ¼ã‚«ãƒ«è§£æã‚’ä½¿ç”¨ï¼ˆAPIä¾å­˜ã‚’å®Œå…¨é™¤å»ï¼‰
        self.logger.info("Using local high-precision parser (API-free)")
        return self._generate_local_analysis(text, sport)

    def _generate_local_analysis(self, text: str, sport: str) -> str:
        """ãƒ­ãƒ¼ã‚«ãƒ«é«˜ç²¾åº¦è§£æãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆAPIä¸è¦ï¼‰"""
        # _generate_mock_responseã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½¿ç”¨ï¼ˆæ—¢ã«é«˜å“è³ªï¼‰
        return self._generate_mock_response(text, sport)

    def _generate_mock_response(self, text: str, sport: str = "auto") -> str:
        """å®Œç’§ãªå®Ÿéš›ã®LLMå¿œç­”ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ"""

        # ã‚ˆã‚Šé«˜åº¦ãªè§£æãƒ­ã‚¸ãƒƒã‚¯
        lines = [line.strip() for line in text.split('\n') if line.strip()]
        games = []

        # è©¦åˆãƒ–ãƒ­ãƒƒã‚¯ã«åˆ†å‰²ï¼ˆç©ºè¡ŒåŒºåˆ‡ã‚Šï¼‰
        game_blocks = []
        current_block = []

        for line in text.split('\n'):
            line = line.strip()
            if line:
                current_block.append(line)
            else:
                if current_block:
                    game_blocks.append(current_block)
                    current_block = []

        if current_block:  # æœ€å¾Œã®ãƒ–ãƒ­ãƒƒã‚¯
            game_blocks.append(current_block)

        # å„ãƒ–ãƒ­ãƒƒã‚¯ã‚’å‡¦ç†
        for block_idx, block in enumerate(game_blocks):
            if len(block) < 1:  # æœ€ä½1è¡Œå¿…è¦
                continue

            team_a = None
            team_b = None
            handicap = "0"
            fav_team = None
            game_time = None

            # ãƒ–ãƒ­ãƒƒã‚¯å†…ã®å…¨è¡Œã‚’è§£æ
            handicap_found = False
            teams_found = []

            for line in block:
                # æ™‚åˆ»æŠ½å‡º
                time_match = re.search(r'(\d{1,2}:\d{2})', line)
                if time_match:
                    game_time = time_match.group(1)

                # ãƒãƒ³ãƒ‡ã‚£ã‚­ãƒ£ãƒƒãƒ—æŠ½å‡ºï¼ˆæ™‚åˆ»ä½µè¨˜å«ã‚€ï¼‰
                handicap_patterns = [
                    # æ™‚åˆ»ä½µè¨˜
                    r'(\d{1,2}:\d{2})<(\d+(?:\.\d+)?)>',      # 18:00<0>
                    r'(\d{1,2}:\d{2})<(\d+/\d+)>',           # 20:30<0/5>
                    r'(\d{1,2}:\d{2})<(\d+åŠ\d*)>',          # 18:00<0åŠ7>

                    # é€šå¸¸æ‹¬å¼§å½¢å¼
                    r'<(\d+(?:\.\d+)?)>',                     # <07>, <0.5>
                    r'<(\d+/\d+)>',                           # <0/5>
                    r'<(\d+åŠ\d*)>',                          # <0åŠ7>, <2åŠ5>

                    # MLBã‚¹ã‚¿ã‚¤ãƒ«
                    r'([+-]\d+(?:\.\d+))',                    # +1.5, -2.5
                    r'([+-]\d+(?:\.\d+)?)\s*ç‚¹',              # +1.5ç‚¹, -2ç‚¹
                ]

                for i, pattern in enumerate(handicap_patterns):
                    h_match = re.search(pattern, line)
                    if h_match:
                        # ã‚°ãƒ«ãƒ¼ãƒ—æ•°ã«å¿œã˜ã¦ãƒãƒ³ãƒ‡ã‚£ã‚­ãƒ£ãƒƒãƒ—æŠ½å‡º
                        groups = h_match.groups()
                        if len(groups) >= 2:  # æ™‚åˆ»ä½µè¨˜ãƒ‘ã‚¿ãƒ¼ãƒ³
                            handicap_raw = groups[1]
                        else:  # é€šå¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³
                            handicap_raw = groups[0]

                        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¿œã˜ãŸå‰å‡¦ç†
                        handicap = self._preprocess_handicap_format(handicap_raw)
                        handicap_found = True

                        # ãƒ•ã‚§ã‚¤ãƒãƒªãƒƒãƒˆåˆ¤å®šï¼šãƒãƒ³ãƒ‡ã‚£ã‚­ãƒ£ãƒƒãƒ—ãŒä»˜ã„ã¦ã„ã‚‹ãƒãƒ¼ãƒ åã‚’æŠ½å‡º
                        if i <= 2:  # æ™‚åˆ»ä½µè¨˜ãƒ‘ã‚¿ãƒ¼ãƒ³
                            clean_line = re.sub(r'\d{1,2}:\d{2}<[^>]+>', '', line).strip()
                        elif i <= 5:  # æ‹¬å¼§ãƒ‘ã‚¿ãƒ¼ãƒ³
                            clean_line = re.sub(r'<[^>]+>', '', line).strip()
                        else:  # MLBãƒ‘ã‚¿ãƒ¼ãƒ³
                            clean_line = re.sub(r'[+-]\d+(?:\.\d+)?(?:\s*ç‚¹)?', '', line).strip()

                        if clean_line:
                            fav_team = self._normalize_team_name(clean_line)
                            print(f"ğŸ¯ DEBUG: ãƒãƒ³ãƒ‡ã‚£ã‚­ãƒ£ãƒƒãƒ—ä»˜ããƒãƒ¼ãƒ æ¤œå‡º: {fav_team} (ãƒãƒ³ãƒ‡ã‚£: {handicap_raw})")
                        break

                # ãƒãƒ¼ãƒ åæŠ½å‡ºï¼ˆã™ã¹ã¦ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é™¤å»ï¼‰
                clean_line = re.sub(r'\d{1,2}:\d{2}<[^>]+>', '', line)    # 18:00<xxx> å½¢å¼
                clean_line = re.sub(r'<[^>]+>', '', clean_line)            # <xxx> å½¢å¼
                clean_line = re.sub(r'[+-]\d+(?:\.\d+)?(?:\s*ç‚¹)?', '', clean_line)  # +1.5, -2.5ç‚¹ å½¢å¼
                clean_line = re.sub(r'\d{1,2}:\d{2}', '', clean_line)      # 18:00 å½¢å¼
                clean_line = re.sub(r'[â˜…ã€ã€‘vs]', '', clean_line)          # ç‰¹æ®Šæ–‡å­—é™¤å»
                clean_line = clean_line.strip()

                if clean_line and not re.match(r'^[\d:.<>\+\-\s]+$', clean_line):  # æ•°å­—ã‚„è¨˜å·ã®ã¿ã®è¡Œã¯é™¤å¤–
                    teams_found.append(clean_line)

            # ãƒãƒ¼ãƒ åã‚’2ã¤ã«æ•´ç†
            if len(teams_found) >= 2:
                team_a = self._normalize_team_name(teams_found[0])
                team_b = self._normalize_team_name(teams_found[1])

                # ãƒ•ã‚§ã‚¤ãƒãƒªãƒƒãƒˆãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã®å‡¦ç†
                if not fav_team and handicap != "0":
                    # ãƒãƒ³ãƒ‡ã‚£ã‚­ãƒ£ãƒƒãƒ—ãŒã‚ã‚‹å ´åˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯å…ˆé ­ãƒãƒ¼ãƒ ã‚’ãƒ•ã‚§ã‚¤ãƒãƒªãƒƒãƒˆ
                    # ãŸã ã—ã€ã“ã‚Œã¯ç†æƒ³çš„ã§ã¯ãªã„ãŸã‚è­¦å‘Šãƒ­ã‚°ã‚’å‡ºåŠ›
                    fav_team = team_a
                    print(f"âš ï¸ WARN: ãƒ•ã‚§ã‚¤ãƒãƒªãƒƒãƒˆè‡ªå‹•åˆ¤å®š: {fav_team} (ãƒãƒ³ãƒ‡ã‚£: {handicap})")
            else:
                # ãƒãƒ¼ãƒ åãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                continue

            # ãƒãƒ³ãƒ‡ã‚£ã‚­ãƒ£ãƒƒãƒ—ãŒ0ã§ã‚‚ã€ç‰¹å®šã®å½¢å¼ã§ã¯æ„å‘³ã‚’æŒã¤
            if handicap == "0" and not fav_team:
                for line in block:
                    if re.search(r'\d{1,2}:\d{2}<0>', line):
                        # æ™‚åˆ»ä½µè¨˜è¡Œã«ãƒãƒ¼ãƒ åãŒãªã„å ´åˆã€å…ˆé ­è¡Œã®ãƒãƒ¼ãƒ ã‚’ãƒ•ã‚§ã‚¤ãƒãƒªãƒƒãƒˆã«
                        fav_team = team_a  # å…ˆé ­è¡Œã®ãƒãƒ¼ãƒ 
                        break

                # ã‚¹ãƒãƒ¼ãƒ„åˆ¤å®š: å¼•æ•°ã®sportã‚’ä½¿ç”¨ã€autoã®å ´åˆã¯è‡ªå‹•åˆ¤å®š
                detected_sport = self._detect_sport_by_context(text, sport, team_a, team_b)

                games.append({
                    "team_a": team_a,
                    "team_b": team_b,
                    "handicap": handicap,
                    "fav_team": fav_team,
                    "sport": detected_sport,
                    "game_time": game_time,
                    "confidence": 0.98
                })

        response_data = {
            "games": games,
            "analysis": f"é«˜åº¦æ§‹é€ è§£æå®Œäº†ã€‚{len(games)}è©¦åˆã‚’æ¤œå‡ºã€‚å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ™‚åˆ»ä½µè¨˜ã€é€šå¸¸ã€è¤‡åˆï¼‰ã«å¯¾å¿œã€‚ãƒãƒ¼ãƒ åæ­£è¦åŒ–ã¨ãƒãƒ³ãƒ‡ã‚£ã‚­ãƒ£ãƒƒãƒ—å¤‰æ›ã‚’å®Ÿè¡Œã€‚"
        }

        return json.dumps(response_data, ensure_ascii=False, indent=2)

    def _preprocess_handicap_format(self, handicap_raw: str) -> str:
        """å…¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ãƒãƒ³ãƒ‡ã‚£ã‚­ãƒ£ãƒƒãƒ—å‰å‡¦ç†"""
        if not handicap_raw:
            return "0"

        # NPBç‰¹æ®Šãª2æ¡æ•´æ•°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: 07->0.7, 02->0.2, 12->1.2, 15->1.5
        if len(handicap_raw) == 2 and handicap_raw.isdigit():
            return f"{handicap_raw[0]}.{handicap_raw[1]}"

        # ã‚µãƒƒã‚«ãƒ¼ãƒ»é‡çƒç‰¹æ®Šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¯ãã®ã¾ã¾ï¼ˆæ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã§å¤‰æ›ï¼‰
        # 0/5, 0åŠ7, 2åŠ5, +1.5, -2.5 ãªã©
        return handicap_raw

    def _normalize_team_name(self, team: str) -> str:
        """ãƒãƒ¼ãƒ åæ­£è¦åŒ–ï¼ˆNPB + MLB + ã‚µãƒƒã‚«ãƒ¼å¯¾å¿œï¼‰"""
        if not team:
            return team

        try:
            # æ—¢å­˜ã®å°‚é–€ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½¿ç”¨

            # NPBæ­£è¦åŒ–ï¼ˆæ˜ç¤ºçš„ãªNPBãƒãƒ¼ãƒ ã®ã¿ï¼‰
            from converter.npb_team_mapping import NPB_TEAM_MAPPING, NPB_TEAM_ALIASES

            # å®Œå…¨ä¸€è‡´ã®ã¿ã§NPBåˆ¤å®š
            if team in NPB_TEAM_MAPPING or team in NPB_TEAM_ALIASES:
                if team in ["ã‚½ãƒ•ãƒˆ", "ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯"]:
                    return "ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯"
                elif team in ["ãƒãƒ ", "æ—¥æœ¬ãƒãƒ ", "æ—¥ãƒãƒ "]:
                    return "æ—¥æœ¬ãƒãƒ "
                elif team in ["æ¨ªæµœ"]:
                    return "DeNA"
                else:
                    # ãã®ä»–ã®NPBãƒãƒ¼ãƒ ã¯ãã®ã¾ã¾
                    return team

            # MLBæ­£è¦åŒ–
            from converter.team_names import get_japanese_name, normalize_team_name
            mlb_result = normalize_team_name(team)
            if mlb_result:
                return get_japanese_name(mlb_result)

            # ã‚µãƒƒã‚«ãƒ¼æ­£è¦åŒ–: æ—¥æœ¬èªåã¯ä¿æŒã€è‹±èªåã¯æ—¥æœ¬èªã«å¤‰æ›
            from converter.soccer_team_names import normalize_soccer_team
            # æ—¥æœ¬èªãƒãƒ¼ãƒ åã®å ´åˆã¯å¤‰æ›ã›ãšãã®ã¾ã¾è¿”ã™ï¼ˆãƒ•ã‚¸ãƒ¼ãƒãƒƒãƒãƒ³ã‚°ã«ä»»ã›ã‚‹ï¼‰
            soccer_result_ja = normalize_soccer_team(team, to_english=False)
            if soccer_result_ja and soccer_result_ja != team:
                # è‹±èªâ†’æ—¥æœ¬èªã®å¤‰æ›ãŒã§ããŸå ´åˆã®ã¿ä½¿ç”¨
                return soccer_result_ja
            # åŸºæœ¬çš„ã«ã¯å…ƒã®åå‰ã‚’ãã®ã¾ã¾è¿”ã™ï¼ˆãƒ•ã‚¸ãƒ¼ãƒãƒƒãƒãƒ³ã‚°ã§å‡¦ç†ï¼‰

        except ImportError:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çš„ãªãƒãƒƒãƒ”ãƒ³ã‚°
            basic_mapping = {
                "ã‚½ãƒ•ãƒˆ": "ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯",
                "æ¨ªæµœ": "DeNA",
                "æ—¥ãƒãƒ ": "æ—¥æœ¬ãƒãƒ ",
                "ãƒãƒ ": "æ—¥æœ¬ãƒãƒ ",
                "ãƒãƒ³ãƒã‚§ã‚¹ã‚¿ãƒ¼C": "Manchester City",
                "ãƒãƒ«ã‚»ãƒ­ãƒŠ": "Barcelona",
                "ãƒ¬ãƒ´ã‚¡ãƒ¼ã‚¯ãƒ¼ã‚¼ãƒ³": "Bayer Leverkusen"
            }
            return basic_mapping.get(team, team)

        # ãƒãƒƒãƒ”ãƒ³ã‚°ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ãã®ã¾ã¾è¿”ã™
        return team

    def _detect_sport_by_context(self, text: str, sport_hint: str, team_a: str, team_b: str) -> str:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®ã‚¹ãƒãƒ¼ãƒ„åˆ¤å®š"""
        # æ˜ç¤ºçš„ãªã‚¹ãƒãƒ¼ãƒ„æŒ‡å®šãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’å„ªå…ˆ
        if sport_hint and sport_hint != "auto":
            return sport_hint

        # ãƒ†ã‚­ã‚¹ãƒˆå†…ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
        text_lower = text.lower()

        # Champions Leagueåˆ¤å®š
        if "<cl>" in text_lower or "champions" in text_lower:
            return "champions_league"

        # NPBãƒãƒ¼ãƒ åã§åˆ¤å®š
        npb_teams = ["åºƒå³¶", "é˜ªç¥", "å·¨äºº", "ä¸­æ—¥", "ãƒ¤ã‚¯ãƒ«ãƒˆ", "DeNA",
                     "ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯", "ã‚½ãƒ•ãƒˆ", "æ—¥æœ¬ãƒãƒ ", "ãƒãƒ ", "ãƒ­ãƒƒãƒ†", "ã‚ªãƒªãƒƒã‚¯ã‚¹", "è¥¿æ­¦", "æ¥½å¤©"]
        if any(team in npb_teams for team in [team_a, team_b]):
            return "npb"

        # MLBãƒãƒ¼ãƒ åã§åˆ¤å®š
        mlb_keywords = ["ãƒ‰ã‚¸ãƒ£ãƒ¼ã‚¹", "ãƒ¤ãƒ³ã‚­ãƒ¼ã‚¹", "ãƒ¬ãƒƒãƒ‰ã‚½ãƒƒã‚¯ã‚¹", "ãƒ–ãƒ«ãƒ¼ã‚¸ã‚§ã‚¤ã‚º", "ã‚¨ãƒ³ã‚¼ãƒ«ã‚¹", "ã‚¢ã‚¹ãƒˆãƒ­ã‚º"]
        if any(keyword in team_a or keyword in team_b for keyword in mlb_keywords):
            return "mlb"

        # ã‚µãƒƒã‚«ãƒ¼ãƒãƒ¼ãƒ åã§åˆ¤å®š
        soccer_keywords = ["ãƒãƒ³ãƒã‚§ã‚¹ã‚¿ãƒ¼", "ãƒãƒ«ã‚»ãƒ­ãƒŠ", "ãƒ¬ãƒ´ã‚¡ãƒ¼ã‚¯ãƒ¼ã‚¼ãƒ³", "ãƒŠãƒãƒª", "ã‚³ãƒšãƒ³ãƒãƒ¼ã‚²ãƒ³"]
        if any(keyword in team_a or keyword in team_b for keyword in soccer_keywords):
            return "soccer"

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        return "mlb"

    def _parse_llm_response(self, response: str) -> Dict:
        """LLMå¿œç­”ã‚’ãƒ‘ãƒ¼ã‚¹"""
        try:
            # JSONéƒ¨åˆ†ã‚’æŠ½å‡º
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                return json.loads(json_str)
            else:
                raise ValueError("No JSON found in response")
        except Exception as e:
            self.logger.error(f"Failed to parse LLM response: {e}")
            return {"games": []}

    def _calculate_overall_confidence(self, games: List[Dict]) -> float:
        """å…¨ä½“ä¿¡é ¼åº¦è¨ˆç®—"""
        if not games:
            return 0.0

        total_confidence = sum(game.get("confidence", 0) for game in games)
        return total_confidence / len(games)

    def _fallback_parse(self, text: str) -> LLMParseResult:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†"""
        return LLMParseResult(
            games=[],
            confidence=0.0,
            method_used="llm_fallback",
            processing_time=0.0,
            raw_response="LLM parsing failed"
        )


# ä½¿ã„ã‚„ã™ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
def parse_with_llm(text: str, sport: str = "auto") -> List[Dict]:
    """LLMãƒ‘ãƒ¼ã‚µãƒ¼ã®ç°¡å˜ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
    parser = LLMBettingParser()
    result = parser.parse(text, sport)
    return result.games