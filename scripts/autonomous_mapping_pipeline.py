#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªå¾‹çš„ãƒãƒƒãƒ”ãƒ³ã‚°æ›´æ–°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
é€±æ¬¡è‡ªå‹•å®Ÿè¡Œ: cron æ¯é€±æ—¥æ›œ 3:00AM
"""

import sys
import json
import subprocess
from pathlib import Path
from datetime import datetime
from typing import Dict, List
import shutil

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent))

from tools.analyze_failure_log import FailureLogAnalyzer
from tools.mapping_candidate_generator import MappingCandidateGenerator


class AutonomousMappingPipeline:
    """è‡ªå¾‹çš„ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’æ›´æ–°ã™ã‚‹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""

    def __init__(self):
        self.base_dir = Path(__file__).parent.parent
        self.unified_teams_path = self.base_dir / "database" / "unified_teams.json"
        self.backup_base = self.base_dir / "backups"
        self.logs_dir = self.base_dir / "logs"
        self.auto_update_log = self.logs_dir / "auto_update_history.json"

    def run(self):
        """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ"""
        print("=" * 80)
        print("ğŸ¤– è‡ªå¾‹ãƒãƒƒãƒ”ãƒ³ã‚°æ›´æ–°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹")
        print(f"   å®Ÿè¡Œæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 80)

        try:
            # STEP 1: æœ€æ–°ãƒãƒ¼ãƒ å–å¾—
            self._step1_fetch_latest_teams()

            # STEP 2: å•é¡Œæ¤œå‡º
            issues = self._step2_detect_issues()

            # STEP 3: å¤±æ•—ãƒ­ã‚°åˆ†æ
            failure_report = self._step3_analyze_failures()

            if not failure_report:
                print("\nâœ… å¤±æ•—ãƒ­ã‚°ãŒç©ºã§ã™ã€‚æ›´æ–°ä¸è¦ã€‚")
                return

            # STEP 4: å€™è£œç”Ÿæˆ
            candidates = self._step4_generate_candidates(failure_report)

            # STEP 5: ä¿¡é ¼åº¦ã§æŒ¯ã‚Šåˆ†ã‘
            categorized = self._step5_categorize_candidates(candidates)

            # STEP 6: é«˜ä¿¡é ¼åº¦ã‚’è‡ªå‹•é©ç”¨
            backup_path = None
            if categorized["high_confidence"]:
                backup_path = self._step6_auto_apply(categorized["high_confidence"])

            # STEP 7: ä¸­ä¿¡é ¼åº¦ã‚’ã‚­ãƒ¥ãƒ¼ã«ä¿å­˜ï¼ˆDiscordé€šçŸ¥ã¯åˆ¥é€”å®Ÿè£…ï¼‰
            if categorized["medium_confidence"]:
                self._step7_save_pending_queue(categorized["medium_confidence"])

            # STEP 8: æ—¢çŸ¥ã®å•é¡Œã‚’ä¿®æ­£
            self._step8_fix_known_issues()

            # STEP 9: æ¤œè¨¼ï¼ˆé«˜ä¿¡é ¼åº¦é©ç”¨ãŒã‚ã£ãŸå ´åˆã®ã¿ï¼‰
            if backup_path:
                self._step9_validate(backup_path)

            print("\n" + "=" * 80)
            print("ğŸ‰ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†")
            print("=" * 80)

        except Exception as e:
            print(f"\nâŒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def _step1_fetch_latest_teams(self):
        """STEP 1: APIæœ€æ–°ãƒãƒ¼ãƒ å–å¾—"""
        print("\nğŸ“¡ STEP 1: APIæœ€æ–°ãƒãƒ¼ãƒ å–å¾—")

        lean_script = self.base_dir / "scripts" / "lean_collect_teams.py"

        if not lean_script.exists():
            print("   âš ï¸  lean_collect_teams.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")
            return

        try:
            result = subprocess.run(
                ["python3", str(lean_script)],
                capture_output=True,
                text=True,
                timeout=60
            )

            if result.returncode == 0:
                # å‡ºåŠ›ã‹ã‚‰å–å¾—ä»¶æ•°ã‚’æŠ½å‡ºï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
                output = result.stdout
                print(f"   âœ… å®Ÿè¡Œå®Œäº†")
                if "å–å¾—" in output:
                    for line in output.split('\n'):
                        if "å–å¾—" in line:
                            print(f"   {line.strip()}")
            else:
                print(f"   âš ï¸  å®Ÿè¡Œå¤±æ•—: {result.stderr}")

        except subprocess.TimeoutExpired:
            print("   âš ï¸  ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ60ç§’ï¼‰")
        except Exception as e:
            print(f"   âš ï¸  ã‚¨ãƒ©ãƒ¼: {e}")

    def _step2_detect_issues(self) -> Dict:
        """STEP 2: ãƒãƒƒãƒ”ãƒ³ã‚°å•é¡Œæ¤œå‡º"""
        print("\nğŸ” STEP 2: ãƒãƒƒãƒ”ãƒ³ã‚°å•é¡Œæ¤œå‡º")

        detect_script = self.base_dir / "tools" / "detect_wrong_mappings.py"

        if not detect_script.exists():
            print("   âš ï¸  detect_wrong_mappings.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")
            return {}

        try:
            result = subprocess.run(
                ["python3", str(detect_script)],
                capture_output=True,
                text=True,
                timeout=30
            )

            # ãƒ¬ãƒãƒ¼ãƒˆèª­ã¿è¾¼ã¿
            report_path = self.logs_dir / "mapping_issues_report.json"
            if report_path.exists():
                with open(report_path, "r", encoding="utf-8") as f:
                    issues = json.load(f)

                print(f"   æ¤œå‡º: {issues.get('total_issues', 0)}ä»¶")
                return issues
            else:
                print("   âœ… å•é¡Œãªã—")
                return {}

        except Exception as e:
            print(f"   âš ï¸  ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    def _step3_analyze_failures(self) -> Dict:
        """STEP 3: å¤±æ•—ãƒ­ã‚°åˆ†æ"""
        print("\nğŸ“Š STEP 3: å¤±æ•—ãƒ­ã‚°åˆ†æï¼ˆéå»7æ—¥ï¼‰")

        analyzer = FailureLogAnalyzer(str(self.logs_dir / "mapping_failures.jsonl"))
        loaded = analyzer.load_log(days=7)

        print(f"   èª­ã¿è¾¼ã¿: {loaded}ã‚¨ãƒ³ãƒˆãƒª")

        if loaded == 0:
            print("   âš ï¸  åˆ†æå¯¾è±¡ãªã—")
            return {}

        report = analyzer.analyze()
        print(f"   åˆ†æ: {len(report)}ãƒãƒ¼ãƒ ")

        return report

    def _step4_generate_candidates(self, failure_report: Dict) -> Dict:
        """STEP 4: ãƒãƒƒãƒ”ãƒ³ã‚°å€™è£œç”Ÿæˆ"""
        print("\nğŸ’¡ STEP 4: ãƒãƒƒãƒ”ãƒ³ã‚°å€™è£œç”Ÿæˆ")

        generator = MappingCandidateGenerator()
        candidates = generator.generate_candidates(failure_report)

        print(f"   å€™è£œç”Ÿæˆ: {len(candidates)}ãƒãƒ¼ãƒ ")

        return candidates

    def _step5_categorize_candidates(self, candidates: Dict) -> Dict:
        """STEP 5: ä¿¡é ¼åº¦ã§æŒ¯ã‚Šåˆ†ã‘"""
        print("\nâš–ï¸  STEP 5: ä¿¡é ¼åº¦ã§æŒ¯ã‚Šåˆ†ã‘")

        high_confidence = {}    # 90ç‚¹ä»¥ä¸Š
        medium_confidence = {}  # 70-89ç‚¹
        low_confidence = {}     # 70ç‚¹æœªæº€

        for api_team, data in candidates.items():
            recommended = data.get("recommended_candidate")

            if not recommended:
                continue

            score = recommended["confidence"]
            japanese = recommended["japanese"]

            if score >= 90:
                high_confidence[api_team] = {
                    "japanese": japanese,
                    "confidence": score,
                    "source": recommended["source"]
                }
            elif score >= 70:
                medium_confidence[api_team] = {
                    "japanese": japanese,
                    "confidence": score,
                    "source": recommended["source"]
                }
            else:
                low_confidence[api_team] = {
                    "japanese": japanese,
                    "confidence": score,
                    "source": recommended["source"]
                }

        print(f"   é«˜ä¿¡é ¼åº¦ï¼ˆè‡ªå‹•é©ç”¨ï¼‰: {len(high_confidence)}ä»¶")
        print(f"   ä¸­ä¿¡é ¼åº¦ï¼ˆãƒ¬ãƒ“ãƒ¥ãƒ¼å¾Œé©ç”¨ï¼‰: {len(medium_confidence)}ä»¶")
        print(f"   ä½ä¿¡é ¼åº¦ï¼ˆæ‰‹å‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼‰: {len(low_confidence)}ä»¶")

        return {
            "high_confidence": high_confidence,
            "medium_confidence": medium_confidence,
            "low_confidence": low_confidence
        }

    def _step6_auto_apply(self, high_confidence: Dict) -> Path:
        """STEP 6: é«˜ä¿¡é ¼åº¦ãƒãƒƒãƒ”ãƒ³ã‚°è‡ªå‹•é©ç”¨"""
        print("\nâœ… STEP 6: é«˜ä¿¡é ¼åº¦ãƒãƒƒãƒ”ãƒ³ã‚°è‡ªå‹•é©ç”¨")

        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
        backup_path = self._create_backup()
        print(f"   ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {backup_path}")

        # unified_teams.json èª­ã¿è¾¼ã¿
        with open(self.unified_teams_path, "r", encoding="utf-8") as f:
            unified_teams = json.load(f)

        # é©ç”¨
        applied_count = 0
        for api_team, data in high_confidence.items():
            japanese = data["japanese"]

            # æ—¢å­˜ã‚¨ãƒ³ãƒˆãƒªã«è¿½åŠ ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼‰
            if api_team in unified_teams:
                if japanese not in unified_teams[api_team]:
                    unified_teams[api_team].append(japanese)
                    applied_count += 1
                    print(f"   + {api_team} â†’ {japanese} (ã‚¹ã‚³ã‚¢: {data['confidence']:.1f})")
            else:
                # æ–°è¦ã‚¨ãƒ³ãƒˆãƒª
                unified_teams[api_team] = [japanese]
                applied_count += 1
                print(f"   + [æ–°è¦] {api_team} â†’ {japanese} (ã‚¹ã‚³ã‚¢: {data['confidence']:.1f})")

        # ä¿å­˜
        with open(self.unified_teams_path, "w", encoding="utf-8") as f:
            json.dump(unified_teams, f, ensure_ascii=False, indent=2)

        print(f"   é©ç”¨: {applied_count}ä»¶")

        # ãƒ­ã‚°è¨˜éŒ²
        self._log_auto_update(high_confidence, "auto_applied")

        return backup_path

    def _step7_save_pending_queue(self, medium_confidence: Dict):
        """STEP 7: ä¸­ä¿¡é ¼åº¦ã‚’ã‚­ãƒ¥ãƒ¼ã«ä¿å­˜"""
        print("\nğŸ“¢ STEP 7: ä¸­ä¿¡é ¼åº¦ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚­ãƒ¥ãƒ¼ã«ä¿å­˜")

        queue_path = self.logs_dir / "pending_review_queue.json"

        # æ—¢å­˜ã‚­ãƒ¥ãƒ¼ã‚’èª­ã¿è¾¼ã¿
        if queue_path.exists():
            with open(queue_path, "r", encoding="utf-8") as f:
                queue = json.load(f)
        else:
            queue = []

        # æ–°è¦å€™è£œã‚’è¿½åŠ 
        timestamp = datetime.now().isoformat()
        for api_team, data in medium_confidence.items():
            queue.append({
                "timestamp": timestamp,
                "api_team": api_team,
                "japanese": data["japanese"],
                "confidence": data["confidence"],
                "source": data["source"],
                "status": "pending_review"
            })

        # ä¿å­˜
        with open(queue_path, "w", encoding="utf-8") as f:
            json.dump(queue, f, ensure_ascii=False, indent=2)

        print(f"   ä¿å­˜: {len(medium_confidence)}ä»¶")
        print(f"   ã‚­ãƒ¥ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«: {queue_path}")

    def _step8_fix_known_issues(self):
        """STEP 8: æ—¢çŸ¥ã®å•é¡Œã‚’ä¿®æ­£"""
        print("\nğŸ”§ STEP 8: æ—¢çŸ¥ã®å•é¡Œã‚’ä¿®æ­£")

        fix_script = self.base_dir / "tools" / "fix_team_database.py"

        if not fix_script.exists():
            print("   âš ï¸  fix_team_database.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")
            return

        try:
            result = subprocess.run(
                ["python3", str(fix_script)],
                capture_output=True,
                text=True,
                timeout=30
            )

            if result.returncode == 0:
                # å‡ºåŠ›ã‹ã‚‰ä¿®æ­£ä»¶æ•°ã‚’æŠ½å‡º
                output = result.stdout
                if "ä¿®æ­£" in output:
                    for line in output.split('\n'):
                        if "ä¿®æ­£" in line:
                            print(f"   {line.strip()}")
                else:
                    print("   âœ… å®Ÿè¡Œå®Œäº†")
            else:
                print(f"   âš ï¸  å®Ÿè¡Œå¤±æ•—: {result.stderr}")

        except Exception as e:
            print(f"   âš ï¸  ã‚¨ãƒ©ãƒ¼: {e}")

    def _step9_validate(self, backup_path: Path):
        """STEP 9: æ›´æ–°å¾Œæ¤œè¨¼ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        print("\nğŸ§ª STEP 9: æ›´æ–°å¾Œæ¤œè¨¼")

        # ç°¡æ˜“æ¤œè¨¼: unified_teams.json ãŒæœ‰åŠ¹ãªJSONã‹ãƒã‚§ãƒƒã‚¯
        try:
            with open(self.unified_teams_path, "r", encoding="utf-8") as f:
                unified_teams = json.load(f)

            team_count = len(unified_teams)
            print(f"   âœ… JSONæ¤œè¨¼OKï¼ˆ{team_count}ãƒãƒ¼ãƒ ï¼‰")

            # TODO: å®Ÿéš›ã®é‹ç”¨ã§ã¯å¤±æ•—ç‡ã‚’ãƒã‚§ãƒƒã‚¯
            # failure_rate_check() ã‚’å®Ÿè£…ã™ã‚‹å ´åˆã¯ã“ã“ã§å®Ÿè¡Œ

        except json.JSONDecodeError as e:
            print(f"   âŒ JSONæ¤œè¨¼å¤±æ•—: {e}")
            print(f"   ğŸ”„ ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œä¸­...")
            self._restore_from_backup(backup_path)
            raise

    def _create_backup(self) -> Path:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = self.backup_base / f"db_backup_{timestamp}"
        backup_dir.mkdir(parents=True, exist_ok=True)

        # unified_teams.json ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        shutil.copy2(
            self.unified_teams_path,
            backup_dir / "unified_teams.json"
        )

        return backup_dir

    def _restore_from_backup(self, backup_path: Path):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒ"""
        backup_file = backup_path / "unified_teams.json"

        if not backup_file.exists():
            print(f"   âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {backup_file}")
            return

        shutil.copy2(backup_file, self.unified_teams_path)
        print(f"   âœ… ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Œäº†: {backup_path}")

    def _log_auto_update(self, updates: Dict, action: str):
        """è‡ªå‹•æ›´æ–°ãƒ­ã‚°ã‚’è¨˜éŒ²"""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "action": action,
            "updates": updates
        }

        # æ—¢å­˜ãƒ­ã‚°èª­ã¿è¾¼ã¿
        if self.auto_update_log.exists():
            with open(self.auto_update_log, "r", encoding="utf-8") as f:
                logs = json.load(f)
        else:
            logs = []

        logs.append(log_entry)

        # ä¿å­˜ï¼ˆæœ€æ–°100ä»¶ã®ã¿ä¿æŒï¼‰
        with open(self.auto_update_log, "w", encoding="utf-8") as f:
            json.dump(logs[-100:], f, ensure_ascii=False, indent=2)


def main():
    """CLIã¨ã—ã¦å®Ÿè¡Œ"""
    pipeline = AutonomousMappingPipeline()
    pipeline.run()


if __name__ == "__main__":
    main()
