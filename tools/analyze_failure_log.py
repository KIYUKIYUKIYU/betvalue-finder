#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤±æ•—ãƒ­ã‚°åˆ†æãƒ„ãƒ¼ãƒ«
mapping_failures.jsonl ã‚’åˆ†æã—ã€é »å‡ºãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º
"""

import json
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List
from collections import defaultdict, Counter


class FailureLogAnalyzer:
    """å¤±æ•—ãƒ­ã‚°ã‚’åˆ†æã—ã€çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""

    def __init__(self, log_path: str):
        self.log_path = Path(log_path)
        self.entries: List[Dict] = []

    def load_log(self, days: int = 7) -> int:
        """
        ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€æŒ‡å®šæ—¥æ•°åˆ†ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼

        Args:
            days: éå»ä½•æ—¥åˆ†ã‚’åˆ†æã™ã‚‹ã‹

        Returns:
            èª­ã¿è¾¼ã‚“ã ã‚¨ãƒ³ãƒˆãƒªæ•°
        """
        if not self.log_path.exists():
            print(f"âš ï¸  ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {self.log_path}")
            return 0

        cutoff_date = datetime.now() - timedelta(days=days)
        self.entries = []

        try:
            with open(self.log_path, "r", encoding="utf-8") as f:
                for line in f:
                    if not line.strip():
                        continue

                    try:
                        entry = json.loads(line)
                        timestamp = datetime.fromisoformat(entry["timestamp"])

                        if timestamp >= cutoff_date:
                            self.entries.append(entry)
                    except (json.JSONDecodeError, KeyError, ValueError) as e:
                        # ä¸æ­£ãªè¡Œã¯ã‚¹ã‚­ãƒƒãƒ—
                        continue

            return len(self.entries)

        except Exception as e:
            print(f"âŒ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return 0

    def analyze(self) -> Dict:
        """
        å¤±æ•—ãƒ­ã‚°ã‚’åˆ†æã—ã€çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ

        Returns:
            {
                "api_team_name": {
                    "api_occurrences": int,
                    "user_inputs": {"æ—¥æœ¬èªå": count},
                    "most_common_input": str,
                    "first_seen": str,
                    "last_seen": str,
                    "failure_types": {"not_in_db": count, "no_match": count}
                }
            }
        """
        if not self.entries:
            return {}

        # api_teamã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        grouped = defaultdict(lambda: {
            "api_occurrences": 0,
            "user_inputs": Counter(),
            "timestamps": [],
            "failure_types": Counter()
        })

        for entry in self.entries:
            api_team = entry.get("api_team", "")
            user_input = entry.get("user_input", "")
            timestamp = entry.get("timestamp", "")
            failure_type = entry.get("failure_type", "unknown")

            if not api_team:
                continue

            grouped[api_team]["api_occurrences"] += 1
            grouped[api_team]["user_inputs"][user_input] += 1
            grouped[api_team]["timestamps"].append(timestamp)
            grouped[api_team]["failure_types"][failure_type] += 1

        # çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = {}
        for api_team, data in grouped.items():
            # æœ€é »å‡ºã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’å–å¾—
            most_common = data["user_inputs"].most_common(1)
            most_common_input = most_common[0][0] if most_common else ""

            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ã‚½ãƒ¼ãƒˆ
            timestamps = sorted(data["timestamps"])

            report[api_team] = {
                "api_occurrences": data["api_occurrences"],
                "user_inputs": dict(data["user_inputs"]),
                "most_common_input": most_common_input,
                "first_seen": timestamps[0] if timestamps else "",
                "last_seen": timestamps[-1] if timestamps else "",
                "failure_types": dict(data["failure_types"])
            }

        return report

    def analyze_last_7_days(self) -> Dict:
        """éå»7æ—¥åˆ†ã‚’åˆ†æï¼ˆä¾¿åˆ©ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰"""
        self.load_log(days=7)
        return self.analyze()

    def print_report(self, report: Dict, top_n: int = 10):
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’è¦‹ã‚„ã™ãè¡¨ç¤º"""
        if not report:
            print("ğŸ“Š åˆ†æçµæœ: ãƒ‡ãƒ¼ã‚¿ãªã—")
            return

        print("\n" + "=" * 80)
        print(f"ğŸ“Š å¤±æ•—ãƒ­ã‚°åˆ†æãƒ¬ãƒãƒ¼ãƒˆ (Top {top_n})")
        print("=" * 80)

        # å‡ºç¾é »åº¦é †ã«ã‚½ãƒ¼ãƒˆ
        sorted_teams = sorted(
            report.items(),
            key=lambda x: x[1]["api_occurrences"],
            reverse=True
        )

        for i, (api_team, data) in enumerate(sorted_teams[:top_n], 1):
            print(f"\n{i}. {api_team}")
            print(f"   APIå‡ºç¾: {data['api_occurrences']}å›")
            print(f"   æœ€é »å‡ºå…¥åŠ›: ã€Œ{data['most_common_input']}ã€")

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®å†…è¨³
            if len(data['user_inputs']) > 1:
                print(f"   å…¥åŠ›ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³:")
                for user_input, count in sorted(
                    data['user_inputs'].items(),
                    key=lambda x: x[1],
                    reverse=True
                ):
                    print(f"     - ã€Œ{user_input}ã€: {count}å›")

            # å¤±æ•—ã‚¿ã‚¤ãƒ—
            failure_summary = ", ".join(
                f"{ftype}({count})"
                for ftype, count in data['failure_types'].items()
            )
            print(f"   å¤±æ•—ã‚¿ã‚¤ãƒ—: {failure_summary}")

        print("\n" + "=" * 80)
        print(f"ç·ãƒãƒ¼ãƒ æ•°: {len(report)}")
        print(f"ç·å¤±æ•—å›æ•°: {sum(d['api_occurrences'] for d in report.values())}")

    def save_report(self, report: Dict, output_path: str):
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)

        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        print(f"ğŸ’¾ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {output_file}")


def main():
    """CLIã¨ã—ã¦å®Ÿè¡Œ"""
    import argparse

    parser = argparse.ArgumentParser(description="å¤±æ•—ãƒ­ã‚°åˆ†æãƒ„ãƒ¼ãƒ«")
    parser.add_argument(
        "--log",
        default="logs/mapping_failures.jsonl",
        help="ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹"
    )
    parser.add_argument(
        "--days",
        type=int,
        default=7,
        help="éå»ä½•æ—¥åˆ†ã‚’åˆ†æã™ã‚‹ã‹"
    )
    parser.add_argument(
        "--output",
        help="ãƒ¬ãƒãƒ¼ãƒˆã®å‡ºåŠ›å…ˆï¼ˆJSONï¼‰"
    )
    parser.add_argument(
        "--top",
        type=int,
        default=10,
        help="è¡¨ç¤ºã™ã‚‹ä¸Šä½Nä»¶"
    )

    args = parser.parse_args()

    print(f"ğŸ” å¤±æ•—ãƒ­ã‚°åˆ†æé–‹å§‹")
    print(f"   å¯¾è±¡: {args.log}")
    print(f"   æœŸé–“: éå»{args.days}æ—¥")

    analyzer = FailureLogAnalyzer(args.log)
    loaded = analyzer.load_log(days=args.days)

    print(f"   èª­ã¿è¾¼ã¿: {loaded}ã‚¨ãƒ³ãƒˆãƒª")

    if loaded == 0:
        print("\nâš ï¸  åˆ†æå¯¾è±¡ã®ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªãŒã‚ã‚Šã¾ã›ã‚“")
        return

    report = analyzer.analyze()
    analyzer.print_report(report, top_n=args.top)

    if args.output:
        analyzer.save_report(report, args.output)


if __name__ == "__main__":
    main()
